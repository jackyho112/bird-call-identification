{"cells":[{"metadata":{"id":"-dUPRjBHmTn9","trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"!pip install tensorflow==2.3.0\n!pip install tensorflow-addons==0.11.1","execution_count":null,"outputs":[]},{"metadata":{"id":"Rm0VkEf5nRTZ","trusted":true},"cell_type":"code","source":"import numpy as np \nimport matplotlib.pyplot as plt\n\nimport tensorflow_addons as tfa\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications import EfficientNetB4\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.optimizers import Adam\nimport random\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n\nfrom sklearn.utils import class_weight as cw","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.__version__","execution_count":null,"outputs":[]},{"metadata":{"id":"9ELkU40gnUds","trusted":true},"cell_type":"code","source":"batch_size = 16\noriginal_img_size = (256, 2000)\nmodel_img_size = 256\nseed = 1\nstorage_dir = '../input/birdmel/train_img_split/train_img_split'\nAUTOTUNE = tf.data.experimental.AUTOTUNE\ncrop_height = model_img_size\ncrop_width = 216","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    storage_dir,\n    validation_split=0.1,\n    subset=\"training\",\n    seed=seed,\n    image_size=original_img_size,\n    batch_size=batch_size,\n    label_mode='categorical'\n)\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    storage_dir,\n    validation_split=0.1,\n    subset=\"validation\",\n    seed=seed,\n    image_size=original_img_size,\n    batch_size=batch_size,\n    label_mode='categorical',\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(num_classes, img_size=model_img_size):\n    inputs = layers.Input(shape=(img_size, img_size, 3))\n    model = EfficientNetB4(include_top=False, input_tensor=inputs)\n\n    x = layers.GlobalMaxPooling2D(name=\"max_pool\")(model.output)\n    x = layers.BatchNormalization()(x)\n\n    top_dropout_rate = 0.5\n    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n\n    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n    model.compile(\n        optimizer=Adam(learning_rate=1e-3), \n        loss=\"categorical_crossentropy\", \n        metrics=[tfa.metrics.F1Score(num_classes = class_num, average = 'micro')]\n    )\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_crop_layer = preprocessing.RandomCrop(crop_height, crop_width)\nrandom_translate_layer = preprocessing.RandomTranslation(height_factor=0, width_factor=0.1, fill_mode='constant')\nrescale_layer = preprocessing.Rescaling(scale=1./255)\nrandom_contrast_layer = preprocessing.RandomContrast(factor=0.1)\ngaussian_noise_layer = layers.GaussianNoise(0.1)\n\ndef resize(image, height=model_img_size, width=model_img_size):\n    return tf.image.resize_with_crop_or_pad(image, target_height=height, target_width=width)\n\ndef mask(image, mask_length=10):\n    insertion_index = int(model_img_size/2)\n    mask_start = int(mask_length/2)\n\n    mask_end_time = crop_width - mask_start + 1\n    mask_offset_time = random.randrange(mask_start, mask_end_time)\n\n    mask_end_freq = crop_height - mask_start + 1\n    mask_offset_freq = random.randrange(mask_start, mask_end_freq)\n    \n    image = tfa.image.cutout(\n        image,\n        mask_size=(model_img_size, mask_length),\n        offset=(insertion_index, mask_offset_time)\n    )\n    \n    image = tfa.image.cutout(\n        image,\n        mask_size=(mask_length, model_img_size),\n        offset=(mask_offset_freq, insertion_index)\n    )\n    \n    return image\n\ndef augment_image_train(image):\n    image = random_crop_layer(image)\n    image = random_contrast_layer(image)\n    image = mask(image)\n    image = random_translate_layer(image)\n    image = gaussian_noise_layer(image, training=True)\n    \n    image = resize(image)\n    image = rescale_layer(image)\n    \n    return image\n\ndef augment_image_test(image):\n    image = resize(image, crop_height, crop_width)\n\n    image = resize(image)\n    image = rescale_layer(image)\n    \n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare(ds, augment=False):\n    # Use data augmentation only on the training set\n    if augment:\n        ds = ds.map(lambda x, y: (augment_image_train(x), y), num_parallel_calls=AUTOTUNE)\n    else: \n        ds = ds.map(lambda x, y: (augment_image_test(x), y), num_parallel_calls=AUTOTUNE)\n\n    # Use buffered prefecting on all datasets\n    return ds.prefetch(buffer_size=AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_num = len(train_ds.class_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = prepare(train_ds, augment=True)\nval_ds = prepare(val_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(dtype=np.float16)\n\ntrain_generator = train_datagen.flow_from_directory(\n    directory=storage_dir,\n    class_mode=\"categorical\",\n    target_size=original_img_size,\n    batch_size=batch_size\n)\n\nclass_weights = cw.compute_class_weight(\n    'balanced',\n    np.unique(train_generator.classes), \n    train_generator.classes\n)\n\nclass_weights = {i : class_weights[i] for i in range(len(class_weights))}\n\ndel train_datagen\ndel train_generator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"net = build_model(class_num, model_img_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net.load_weights( '../input/birdmel/efficientnet_b4_checkpoint_tf_2_3_0.h5')","execution_count":null,"outputs":[]},{"metadata":{"id":"z7J4bbcpnywH","executionInfo":{"status":"ok","timestamp":1596332537283,"user_tz":420,"elapsed":26355,"user":{"displayName":"Jacky Ho","photoUrl":"","userId":"11519507165979664806"}},"outputId":"29c8900f-b2e0-4e7f-d225-7130f4ad09e4","trusted":true},"cell_type":"code","source":"model_check = ModelCheckpoint(\n    'efficientnet_b4_checkpoint_tf_2_3_0.h5', \n    monitor='val_f1_score', \n    verbose=0, \n    save_best_only=True, \n    save_weights_only=True,\n    mode='max',\n    period=1,\n)\n\n\nreduce_LR = ReduceLROnPlateau(\n    monitor='val_f1_score',\n    factor=0.2,\n    patience=5, \n    min_lr=5e-5\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net.fit(\n    train_ds,\n    validation_data = val_ds,\n    epochs = 100,\n    class_weight = class_weights,\n    callbacks = [reduce_LR, model_check]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}